{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Imports Required Go Here\n",
    "\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "# Data from the John Hopkins University Dataset on GitHub\n",
    "# https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "\n",
    "# Defining the variables required\n",
    "filenames = ['time_series_covid19_confirmed_global.csv',\n",
    "             'time_series_covid19_deaths_global.csv',\n",
    "             'time_series_covid19_recovered_global.csv']\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "\n",
    "# Making the main dataframes required for the analysis\n",
    "confirmed_global = pd.read_csv(url + filenames[0])\n",
    "deaths_global = pd.read_csv(url + filenames[1])\n",
    "recovered_global = pd.read_csv(url + filenames[2])\n",
    "country_cases = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/web-data/data/cases_country.csv')\n",
    "\n",
    "# Simple Data Cleaning - Removing and renaming the Columns\n",
    "\n",
    "# Removing the Province/State column, as it is pretty much not of any use\n",
    "confirmed_global.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "deaths_global.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "recovered_global.drop(columns = ['Province/State', 'Lat', 'Long'], inplace = True)\n",
    "\n",
    "# Renaming the columns for easier access\n",
    "confirmed_global.rename(columns = {\"Country/Region\": \"country\"}, inplace = True)\n",
    "deaths_global.rename(columns = {\"Country/Region\": \"country\"}, inplace = True)\n",
    "recovered_global.rename(columns = {\"Country/Region\": \"country\"}, inplace = True)\n",
    "\n",
    "country_cases.rename(columns = {\n",
    "    \"Country_Region\" : \"country\",\n",
    "    \"Last_Update\": \"last\",\n",
    "    \"Confirmed\": \"confirmed\",\n",
    "    \"Deaths\": \"deaths\",\n",
    "    \"Recovered\" : \"recovered\",\n",
    "    \"Active\" : \"active\",\n",
    "    \"Mortality_Rate\": \"mortality\"\n",
    "}, inplace = True)\n",
    "\n",
    "# Removing some duplicate values from the table\n",
    "confirmed_global = confirmed_global.groupby(['country'], as_index = False).sum()\n",
    "deaths_global = deaths_global.groupby(['country'], as_index = False).sum()\n",
    "recovered_global = recovered_global.groupby(['country'], as_index = False).sum()\n",
    "\n",
    "# This value is being changed as there was an error in the original dataset that had to be modified\n",
    "confirmed_global.at[178, '5/20/20'] = 251667\n",
    "\n",
    "# Making a dataframe with the country data in sorted order\n",
    "country_cases_sorted = country_cases.sort_values('confirmed', ascending = False)\n",
    "country_cases_sorted.index = [x for x in range(len(country_cases_sorted))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
